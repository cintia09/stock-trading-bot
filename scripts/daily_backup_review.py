#!/usr/bin/env python3
"""
æ¯æ—¥å¤ç›˜æ•°æ®å¤‡ä»½ + å›æµ‹éªŒè¯
æ¯å¤©æ”¶ç›˜åè¿è¡Œï¼Œä¿å­˜æ•°æ®å¹¶éªŒè¯ç­–ç•¥è¡¨ç°
"""

import json
import shutil
from datetime import datetime, timedelta
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent))

from fetch_stock_data import fetch_kline, fetch_realtime_sina, fetch_market_overview
from deep_review_v2 import DeepReviewV2
from backtest import BacktestEngine

# è·¯å¾„é…ç½®
WORKSPACE = Path(__file__).parent.parent
BACKUP_ROOT = Path("/root/backups/stock-trading")
BACKUP_ROOT.mkdir(parents=True, exist_ok=True)

# å¤‡ä»½å­ç›®å½•
SNAPSHOTS_DIR = BACKUP_ROOT / "daily-snapshots"
KLINE_CACHE_DIR = BACKUP_ROOT / "kline-cache"
REVIEWS_DIR = BACKUP_ROOT / "reviews"

for d in [SNAPSHOTS_DIR, KLINE_CACHE_DIR, REVIEWS_DIR]:
    d.mkdir(exist_ok=True)


class DailyBackupAndReview:
    """æ¯æ—¥å¤‡ä»½å’Œå¤ç›˜"""
    
    def __init__(self):
        self.today = datetime.now().strftime("%Y-%m-%d")
        self.account_file = WORKSPACE / "account.json"
        self.transactions_file = WORKSPACE / "transactions.json"
        self.params_file = WORKSPACE / "strategy_params.json"
        self.watchlist_file = WORKSPACE / "watchlist.json"
    
    def load_json(self, path: Path) -> dict:
        if path.exists():
            with open(path, 'r') as f:
                return json.load(f)
        return {}
    
    def save_json(self, path: Path, data: dict):
        with open(path, 'w') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def backup_daily_snapshot(self) -> str:
        """å¤‡ä»½å½“æ—¥å¿«ç…§"""
        snapshot = {
            "date": self.today,
            "timestamp": datetime.now().isoformat(),
            "account": self.load_json(self.account_file),
            "transactions": self.load_json(self.transactions_file),
            "strategy_params": self.load_json(self.params_file),
            "watchlist": self.load_json(self.watchlist_file),
        }
        
        # è·å–å¸‚åœºæ•°æ®
        snapshot["market"] = fetch_market_overview()
        
        # è·å–æŒä»“å®æ—¶ä»·æ ¼
        account = snapshot["account"]
        holdings = account.get("holdings", [])
        if holdings:
            codes = [h["code"] for h in holdings]
            snapshot["realtime_prices"] = fetch_realtime_sina(codes)
        
        # è®¡ç®—å½“æ—¥ç›ˆäº
        total_value = account.get("current_cash", 0)
        for h in holdings:
            code = h["code"]
            price = snapshot.get("realtime_prices", {}).get(code, {}).get("price", h["cost_price"])
            total_value += price * h["quantity"]
        
        snapshot["total_value"] = total_value
        snapshot["daily_pnl"] = total_value - account.get("initial_capital", 1000000)
        snapshot["daily_pnl_pct"] = snapshot["daily_pnl"] / account.get("initial_capital", 1000000) * 100
        
        # ä¿å­˜
        snapshot_file = SNAPSHOTS_DIR / f"snapshot_{self.today}.json"
        self.save_json(snapshot_file, snapshot)
        
        print(f"âœ… å¿«ç…§å·²ä¿å­˜: {snapshot_file}")
        return str(snapshot_file)
    
    def backup_kline_data(self) -> str:
        """å¤‡ä»½æŒä»“è‚¡ç¥¨çš„Kçº¿æ•°æ®"""
        account = self.load_json(self.account_file)
        holdings = account.get("holdings", [])
        
        kline_backup = {
            "date": self.today,
            "stocks": {}
        }
        
        for h in holdings:
            code = h["code"]
            name = h["name"]
            print(f"  è·å– {name} ({code}) Kçº¿...")
            klines = fetch_kline(code, limit=120)
            if klines:
                kline_backup["stocks"][code] = {
                    "name": name,
                    "klines": klines
                }
        
        kline_file = KLINE_CACHE_DIR / f"klines_{self.today}.json"
        self.save_json(kline_file, kline_backup)
        
        print(f"âœ… Kçº¿æ•°æ®å·²å¤‡ä»½: {kline_file}")
        return str(kline_file)
    
    def run_review_with_backtest(self) -> dict:
        """è¿è¡Œå¤ç›˜å¹¶è¿›è¡Œå›æµ‹éªŒè¯"""
        
        results = {
            "date": self.today,
            "review": None,
            "backtest": None,
            "comparison": None
        }
        
        # 1. è¿è¡Œ 5-Why æ·±åº¦å¤ç›˜
        print("\nğŸ“Š è¿è¡Œ 5-Why æ·±åº¦å¤ç›˜...")
        reviewer = DeepReviewV2()
        review_report = reviewer.run_review()
        results["review"] = review_report
        
        # ä¿å­˜å¤ç›˜æŠ¥å‘Š
        review_file = REVIEWS_DIR / f"review_{self.today}.md"
        with open(review_file, 'w') as f:
            f.write(review_report)
        print(f"âœ… å¤ç›˜æŠ¥å‘Šå·²ä¿å­˜: {review_file}")
        
        # 2. è¿è¡Œå›æµ‹éªŒè¯å½“å‰ç­–ç•¥
        print("\nğŸ“ˆ è¿è¡Œç­–ç•¥å›æµ‹...")
        account = self.load_json(self.account_file)
        holdings = account.get("holdings", [])
        
        if holdings:
            stocks = [{"code": h["code"], "name": h["name"]} for h in holdings]
            
            # å›æµ‹æœ€è¿‘60å¤©
            end_date = self.today
            start_date = (datetime.now() - timedelta(days=60)).strftime("%Y-%m-%d")
            
            engine = BacktestEngine(initial_capital=1000000)
            backtest_result = engine.run_backtest(
                stocks=stocks,
                start_date=start_date,
                end_date=end_date,
                strategy_name=f"å½“å‰ç­–ç•¥_{self.today}"
            )
            
            if backtest_result:
                engine.print_result(backtest_result)
                backtest_file = engine.save_result(backtest_result)
                
                # å¤åˆ¶åˆ°å¤‡ä»½ç›®å½•
                shutil.copy(backtest_file, REVIEWS_DIR / f"backtest_{self.today}.json")
                
                results["backtest"] = {
                    "total_return": backtest_result.total_return,
                    "annual_return": backtest_result.annual_return,
                    "max_drawdown": backtest_result.max_drawdown,
                    "win_rate": backtest_result.win_rate,
                    "profit_factor": backtest_result.profit_factor,
                    "sharpe_ratio": backtest_result.sharpe_ratio
                }
        
        # 3. ä¸å†å²å›æµ‹å¯¹æ¯”
        print("\nğŸ“Š ä¸å†å²å¯¹æ¯”...")
        results["comparison"] = self.compare_with_history()
        
        return results
    
    def compare_with_history(self) -> dict:
        """ä¸å†å²å›æµ‹ç»“æœå¯¹æ¯”"""
        
        backtest_files = sorted(REVIEWS_DIR.glob("backtest_*.json"))
        
        if len(backtest_files) < 2:
            return {"message": "å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•å¯¹æ¯”"}
        
        history = []
        for f in backtest_files[-7:]:  # æœ€è¿‘7æ¬¡
            with open(f, 'r') as fp:
                data = json.load(fp)
                history.append({
                    "date": f.stem.replace("backtest_", ""),
                    "return": data.get("total_return", 0),
                    "win_rate": data.get("win_rate", 0),
                    "max_drawdown": data.get("max_drawdown", 0)
                })
        
        # è®¡ç®—è¶‹åŠ¿
        if len(history) >= 2:
            recent = history[-1]
            previous = history[-2]
            
            return {
                "recent": recent,
                "previous": previous,
                "return_trend": "improving" if recent["return"] > previous["return"] else "declining",
                "win_rate_trend": "improving" if recent["win_rate"] > previous["win_rate"] else "declining",
                "history_count": len(history)
            }
        
        return {"message": "éœ€è¦æ›´å¤šæ•°æ®"}
    
    def get_historical_stats(self) -> dict:
        """è·å–å†å²ç»Ÿè®¡"""
        snapshots = sorted(SNAPSHOTS_DIR.glob("snapshot_*.json"))
        
        if not snapshots:
            return {"message": "æ— å†å²æ•°æ®"}
        
        daily_pnls = []
        for f in snapshots:
            with open(f, 'r') as fp:
                data = json.load(fp)
                daily_pnls.append({
                    "date": data.get("date"),
                    "pnl": data.get("daily_pnl", 0),
                    "pnl_pct": data.get("daily_pnl_pct", 0)
                })
        
        if daily_pnls:
            import statistics
            pnl_values = [d["pnl"] for d in daily_pnls]
            return {
                "total_days": len(daily_pnls),
                "total_pnl": sum(pnl_values),
                "avg_daily_pnl": statistics.mean(pnl_values),
                "best_day": max(daily_pnls, key=lambda x: x["pnl"]),
                "worst_day": min(daily_pnls, key=lambda x: x["pnl"]),
                "winning_days": len([p for p in pnl_values if p > 0]),
                "losing_days": len([p for p in pnl_values if p < 0])
            }
        
        return {"message": "æ•°æ®ä¸ºç©º"}
    
    def run_full_daily_process(self) -> str:
        """è¿è¡Œå®Œæ•´çš„æ¯æ—¥å¤‡ä»½å’Œå¤ç›˜æµç¨‹"""
        
        print("=" * 60)
        print(f"ğŸ“… æ¯æ—¥å¤ç›˜å’Œå¤‡ä»½ | {self.today}")
        print("=" * 60)
        
        # 1. å¤‡ä»½å¿«ç…§
        print("\nğŸ“¦ å¤‡ä»½å½“æ—¥å¿«ç…§...")
        self.backup_daily_snapshot()
        
        # 2. å¤‡ä»½Kçº¿
        print("\nğŸ“ˆ å¤‡ä»½Kçº¿æ•°æ®...")
        self.backup_kline_data()
        
        # 3. è¿è¡Œå¤ç›˜+å›æµ‹
        results = self.run_review_with_backtest()
        
        # 4. è·å–å†å²ç»Ÿè®¡
        print("\nğŸ“Š å†å²ç»Ÿè®¡...")
        historical = self.get_historical_stats()
        print(f"  ç´¯è®¡äº¤æ˜“æ—¥: {historical.get('total_days', 0)}")
        print(f"  ç´¯è®¡ç›ˆäº: Â¥{historical.get('total_pnl', 0):,.0f}")
        
        # 5. ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        summary = self.generate_summary(results, historical)
        
        # ä¿å­˜æ±‡æ€»
        summary_file = REVIEWS_DIR / f"summary_{self.today}.md"
        with open(summary_file, 'w') as f:
            f.write(summary)
        
        print(f"\nâœ… æ±‡æ€»æŠ¥å‘Š: {summary_file}")
        print("\n" + summary)
        
        return summary
    
    def generate_summary(self, results: dict, historical: dict) -> str:
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        
        lines = []
        lines.append(f"# ğŸ“Š æ¯æ—¥å¤ç›˜æ±‡æ€» | {self.today}")
        lines.append("")
        
        # å›æµ‹ç»“æœ
        if results.get("backtest"):
            bt = results["backtest"]
            lines.append("## ğŸ“ˆ ç­–ç•¥å›æµ‹éªŒè¯")
            emoji = "ğŸŸ¢" if bt["total_return"] >= 0 else "ğŸ”´"
            lines.append(f"- {emoji} æ”¶ç›Šç‡: {bt['total_return']*100:+.2f}%")
            lines.append(f"- ğŸ“‰ æœ€å¤§å›æ’¤: {bt['max_drawdown']*100:.2f}%")
            lines.append(f"- ğŸ¯ èƒœç‡: {bt['win_rate']*100:.1f}%")
            lines.append(f"- âš–ï¸ ç›ˆäºæ¯”: {bt['profit_factor']:.2f}")
            lines.append(f"- ğŸ“Š å¤æ™®: {bt['sharpe_ratio']:.2f}")
            lines.append("")
        
        # ä¸å†å²å¯¹æ¯”
        if results.get("comparison") and results["comparison"].get("return_trend"):
            comp = results["comparison"]
            lines.append("## ğŸ“Š ä¸ä¸Šæ¬¡å¯¹æ¯”")
            lines.append(f"- æ”¶ç›Šè¶‹åŠ¿: {'ğŸ“ˆ æ”¹å–„' if comp['return_trend'] == 'improving' else 'ğŸ“‰ ä¸‹é™'}")
            lines.append(f"- èƒœç‡è¶‹åŠ¿: {'ğŸ“ˆ æ”¹å–„' if comp['win_rate_trend'] == 'improving' else 'ğŸ“‰ ä¸‹é™'}")
            lines.append("")
        
        # å†å²ç»Ÿè®¡
        if historical.get("total_days"):
            lines.append("## ğŸ“… ç´¯è®¡ç»Ÿè®¡")
            lines.append(f"- äº¤æ˜“æ—¥: {historical['total_days']} å¤©")
            lines.append(f"- ç´¯è®¡ç›ˆäº: Â¥{historical['total_pnl']:+,.0f}")
            lines.append(f"- æ—¥å‡ç›ˆäº: Â¥{historical['avg_daily_pnl']:+,.0f}")
            lines.append(f"- ç›ˆåˆ©å¤©æ•°: {historical['winning_days']} | äºæŸå¤©æ•°: {historical['losing_days']}")
            lines.append("")
        
        return "\n".join(lines)


def main():
    processor = DailyBackupAndReview()
    summary = processor.run_full_daily_process()
    return summary


if __name__ == "__main__":
    main()
